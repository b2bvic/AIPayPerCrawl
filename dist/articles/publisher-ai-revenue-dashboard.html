<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Build a Publisher AI Revenue Dashboard: Track Licensing Income, Traffic Impact, and ROI Metrics | AI Pay Per Crawl</title>
    <meta name="description" content="Executive dashboard tracking AI licensing revenue streams, crawler-induced traffic displacement, negotiation pipeline value, and net profitability across multiple AI partnerships.">
    <meta name="author" content="Victor Valentine Romo">
    <meta name="robots" content="index, follow">
    <meta property="og:title" content="Build a Publisher AI Revenue Dashboard: Track Licensing Income, Traffic Impact, and ROI Metrics">
    <meta property="og:description" content="Executive dashboard tracking AI licensing revenue streams, crawler-induced traffic displacement, negotiation pipeline value, and net profitability across multiple AI partnerships.">
    <meta property="og:type" content="article">
    <meta property="og:url" content="https://aipaypercrawl.com/articles/publisher-ai-revenue-dashboard">
    <meta property="og:site_name" content="AI Pay Per Crawl">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="Build a Publisher AI Revenue Dashboard: Track Licensing Income, Traffic Impact, and ROI Metrics">
    <meta name="twitter:description" content="Executive dashboard tracking AI licensing revenue streams, crawler-induced traffic displacement, negotiation pipeline value, and net profitability across multiple AI partnerships.">
    <link rel="canonical" href="https://aipaypercrawl.com/articles/publisher-ai-revenue-dashboard">
    <script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "TechArticle",
  "headline": "Build a Publisher AI Revenue Dashboard: Track Licensing Income, Traffic Impact, and ROI Metrics",
  "description": "Executive dashboard tracking AI licensing revenue streams, crawler-induced traffic displacement, negotiation pipeline value, and net profitability across multiple AI partnerships.",
  "author": {
    "@type": "Person",
    "@id": "https://victorvalentineromo.com/#person",
    "name": "Victor Valentine Romo",
    "url": "https://victorvalentineromo.com"
  },
  "publisher": {
    "@type": "Organization",
    "@id": "https://aipaypercrawl.com/#organization",
    "name": "AI Pay Per Crawl",
    "url": "https://aipaypercrawl.com"
  },
  "datePublished": "2026-02-08",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://aipaypercrawl.com/articles/publisher-ai-revenue-dashboard"
  }
}
    </script>
    <script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position": 1,
      "name": "Home",
      "item": "https://aipaypercrawl.com"
    },
    {
      "@type": "ListItem",
      "position": 2,
      "name": "Articles",
      "item": "https://aipaypercrawl.com/articles.html"
    },
    {
      "@type": "ListItem",
      "position": 3,
      "name": "Build a Publisher AI Revenue Dashboard: Track Licensing Income, Traffic Impact, and ROI Metrics",
      "item": "https://aipaypercrawl.com/articles/publisher-ai-revenue-dashboard"
    }
  ]
}
    </script>

    <link rel="icon" type="image/svg+xml" href="data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 100 100'><rect fill='%234f46e5' width='100' height='100' rx='12'/><text x='50' y='70' font-family='monospace' font-size='38' font-weight='700' fill='%23ffffff' text-anchor='middle'>APC</text></svg>">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;500;600;700&family=IBM+Plex+Sans:wght@400;500;600&display=swap">
    <link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;500;600;700&family=IBM+Plex+Sans:wght@400;500;600&display=swap" rel="stylesheet" media="print" onload="this.media='all'">
    <noscript><link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;500;600;700&family=IBM+Plex+Sans:wght@400;500;600&display=swap" rel="stylesheet"></noscript>
    <link rel="stylesheet" href="/base.css">
    <link rel="me" href="https://scalewithsearch.com">
    <link rel="me" href="https://victorvalentineromo.com">
    <link rel="me" href="https://aifirstsearch.com">
    <link rel="me" href="https://browserprompt.com">
    <link rel="me" href="https://creatinepedia.com">
    <link rel="me" href="https://polytraffic.com">
    <link rel="me" href="https://tattooremovalnear.com">
    <link rel="me" href="https://comicstripai.com">
    <link rel="me" href="https://aipaypercrawl.com">
    <link rel="me" href="https://b2bvic.com">
    <link rel="me" href="https://seobyrole.com">
    <link rel="me" href="https://quickfixseo.com">
</head>
<body>


  <nav class="nav" role="navigation" aria-label="Primary">
    <div class="nav__inner">
      <a href="/" class="nav__logo">APC</a>

      <div class="nav__links">
        <!-- Implementation dropdown -->
        <div class="mega-wrapper" data-mega="implementation">
          <button class="nav__link mega-trigger" aria-expanded="false" aria-controls="mega-implementation">
            Implementation
            <svg fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/></svg>
          </button>
        </div>

        <!-- Pricing dropdown -->
        <div class="mega-wrapper" data-mega="pricing">
          <button class="nav__link mega-trigger" aria-expanded="false" aria-controls="mega-pricing">
            Pricing
            <svg fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/></svg>
          </button>
        </div>

        <!-- Crawlers dropdown -->
        <div class="mega-wrapper" data-mega="crawlers">
          <button class="nav__link mega-trigger" aria-expanded="false" aria-controls="mega-crawlers">
            Crawlers
            <svg fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/></svg>
          </button>
        </div>

        <!-- Legal (direct link) -->
        <a href="/articles.html" class="nav__link">Legal</a>

        <div class="nav__divider"></div>

        <a href="/setup.html" class="nav__cta">Master the Protocol &mdash; $2,497</a>
      </div>

      <button class="nav__mobile-btn" id="mobile-menu-btn" aria-label="Open menu">
        <svg id="menu-icon" width="24" height="24" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16M4 18h16"/></svg>
        <svg id="close-icon" class="hidden" width="24" height="24" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18L18 6M6 6l12 12"/></svg>
      </button>
    </div>

    <!-- Mega Panel: Implementation -->
    <div id="mega-implementation" class="mega-panel" role="region" aria-label="Implementation guides">
      <div class="mega-panel__inner">
        <div>
          <div class="mega-column__label">Infrastructure</div>
          <a href="/articles.html" class="mega-link">Cloudflare Setup</a>
          <a href="/articles.html" class="mega-link">Nginx Rules</a>
          <a href="/articles.html" class="mega-link">Apache Config</a>
          <a href="/articles.html" class="mega-link">WordPress Plugin</a>
          <a href="/articles.html" class="mega-link">CDN Integration</a>
        </div>
        <div>
          <div class="mega-column__label">Protocols</div>
          <a href="/articles.html" class="mega-link">RSL Protocol</a>
          <a href="/articles.html" class="mega-link">llms.txt Specification</a>
          <a href="/articles.html" class="mega-link">robots.txt for AI</a>
          <a href="/articles.html" class="mega-link">Machine-Readable Terms</a>
        </div>
        <div>
          <div class="mega-column__label">Quick Start</div>
          <div style="background: linear-gradient(135deg, rgba(16,185,129,0.06), rgba(79,70,229,0.04)); border: 1px solid rgba(16,185,129,0.2); border-radius: 12px; padding: 1.5rem;">
            <h3 style="font-family: var(--font-display); font-size: 1.125rem; font-weight: 600; color: var(--text-primary); margin-bottom: 0.5rem;">Skip the learning curve.</h3>
            <p style="font-size: 0.875rem; color: var(--text-secondary); margin-bottom: 1rem;">Complete pay-per-crawl implementation. Templates, pricing, contracts.</p>
            <a href="/setup.html" class="btn btn--primary" style="font-size: 0.8125rem; padding: 0.625rem 1.25rem;">Get Rule &mdash; $2,497</a>
          </div>
        </div>
      </div>
    </div>

    <!-- Mega Panel: Pricing -->
    <div id="mega-pricing" class="mega-panel" role="region" aria-label="Pricing models">
      <div class="mega-panel__inner">
        <div>
          <div class="mega-column__label">Models</div>
          <a href="/articles.html" class="mega-link">Per-Crawl Pricing</a>
          <a href="/articles.html" class="mega-link">Flat-Rate Annual</a>
          <a href="/articles.html" class="mega-link">Tiered Pricing</a>
          <a href="/articles.html" class="mega-link">Volume Discounts</a>
          <a href="/articles.html" class="mega-link">Hybrid Models</a>
        </div>
        <div>
          <div class="mega-column__label">Benchmarks</div>
          <a href="/articles.html" class="mega-link">Rate Cards by Content Type</a>
          <a href="/articles.html" class="mega-link">Revenue Calculators</a>
          <a href="/articles.html" class="mega-link">Industry Benchmarks</a>
          <a href="/articles.html" class="mega-link">Deal Comparisons</a>
        </div>
        <div>
          <div class="mega-column__label">Recent Deals</div>
          <a href="/articles.html" class="mega-link">News Corp &times; OpenAI ($250M)</a>
          <a href="/articles.html" class="mega-link">Reddit &times; Google ($60M/yr)</a>
          <a href="/articles.html" class="mega-link">FT &times; Anthropic</a>
          <a href="/articles.html" class="mega-link">AP &times; OpenAI</a>
        </div>
      </div>
    </div>

    <!-- Mega Panel: Crawlers -->
    <div id="mega-crawlers" class="mega-panel" role="region" aria-label="Crawler information">
      <div class="mega-panel__inner">
        <div>
          <div class="mega-column__label">Major Crawlers</div>
          <a href="/articles.html" class="mega-link">GPTBot (OpenAI)</a>
          <a href="/articles.html" class="mega-link">ClaudeBot (Anthropic)</a>
          <a href="/articles.html" class="mega-link">Googlebot-Extended</a>
          <a href="/articles.html" class="mega-link">Bytespider (ByteDance)</a>
          <a href="/articles.html" class="mega-link">CCBot (Common Crawl)</a>
        </div>
        <div>
          <div class="mega-column__label">Detection</div>
          <a href="/articles.html" class="mega-link">Bot Detection Methods</a>
          <a href="/articles.html" class="mega-link">User Agent Reference</a>
          <a href="/articles.html" class="mega-link">IP Range Verification</a>
          <a href="/articles.html" class="mega-link">Compliance Rates</a>
        </div>
        <div>
          <div class="mega-column__label">Directory</div>
          <a href="/articles.html" class="mega-link">Full Crawler Directory</a>
          <a href="/articles.html" class="mega-link">Crawler Behavior Matrix</a>
          <a href="/articles.html" class="mega-link">robots.txt Respect Rates</a>
        </div>
      </div>
    </div>

    <!-- Mobile Menu -->
    <div id="mobile-menu" class="mobile-menu">
      <a href="/articles.html" class="mobile-menu__link">Implementation</a>
      <a href="/articles.html" class="mobile-menu__link">Pricing</a>
      <a href="/articles.html" class="mobile-menu__link">Crawlers</a>
      <a href="/articles.html" class="mobile-menu__link">Legal</a>
      <a href="/articles.html" class="mobile-menu__link">All Articles</a>
      <a href="/setup.html" class="mobile-menu__cta">Master the Protocol &mdash; $2,497</a>
    </div>
  </nav>

  <main class="pt-nav">
    <div class="container--narrow" style="padding-top: var(--sp-8);">
      <div class="breadcrumbs">
        <a href="/">Home</a><span class="breadcrumbs__sep">/</span>
        <a href="/articles.html">Articles</a><span class="breadcrumbs__sep">/</span>
        <span>Build a Publisher AI Revenue Dashboard: Track Licensing Income, Traffic Impact, and ROI Metrics</span>
      </div>

      <header style="margin-bottom: var(--sp-12);">
        <span class="label" style="margin-bottom: var(--sp-4); display: block;">Article &middot; 14 min read</span>
        <h1>Build a Publisher AI Revenue Dashboard: Track Licensing Income, Traffic Impact, and ROI Metrics</h1>
        <p style="font-size: 1.125rem; color: var(--text-secondary); margin-top: var(--sp-4); max-width: 640px;">Executive dashboard tracking AI licensing revenue streams, crawler-induced traffic displacement, negotiation pipeline value, and net profitability across multiple AI partnerships.</p>
      </header>

      <article class="article-body">
        <h1>Build a Publisher AI Revenue Dashboard: Track Licensing Income, Traffic Impact, and ROI Metrics</h1>
<p><strong>Publishers managing AI licensing portfolios across 3-8 simultaneous partnerships lack unified visibility into financial performance.</strong> Revenue arrives via different payment schedules (monthly, quarterly, annual), traffic impact varies by crawler behavior and licensing terms, and profitability calculations require attributing infrastructure costs, legal fees, and opportunity costs against gross licensing income.</p>
<p><strong>Executive dashboards</strong> consolidate these fragmented data streams into single-page visibility. Decision-makers assess at a glance: total AI licensing revenue (trailing 12 months and projected forward), revenue per AI partner with growth trends, traffic displacement quantified in lost pageviews and ad revenue, cost attribution showing net profitability, and pipeline value tracking negotiations in progress.</p>
<p>This guide implements production-grade dashboards using Google Sheets (accessible option) or Grafana + PostgreSQL (enterprise option). Both approaches connect to data sources publishers already operate: web analytics platforms, server access logs, accounting systems, and CRM tools tracking licensing negotiations.</p>
<h2>Dashboard Architecture: Data Sources and Integration Points</h2>
<p><strong>Four core data sources</strong> feed AI revenue dashboards: financial data (invoices, payments received), web analytics (traffic volumes, user behavior), server infrastructure (crawler activity logs, bandwidth costs), and business intelligence (deal pipeline, negotiation stages).</p>
<p><strong>Financial data integration</strong> typically originates from accounting software (QuickBooks, Xero, NetSuite) or manual invoice tracking spreadsheets. Key metrics extracted:</p>
<ul>
<li><strong>Invoice date, payment due date, payment received date</strong> — track payment timing and identify late payments</li>
<li><strong>Invoice amount, payment amount</strong> — gross revenue per deal</li>
<li><strong>AI company identifier</strong> — attribute revenue to specific partnerships</li>
<li><strong>Contract period</strong> — annual vs. multi-year deals, renewal dates</li>
<li><strong>Payment terms</strong> — net-30, net-60, quarterly installments</li>
<li><strong>Deal type</strong> — fixed annual fee, consumption-based, hybrid structure</li>
</ul>
<p>Export this data monthly as CSV from your accounting system. Structure format:</p>
<pre><code>deal_id,ai_company,invoice_date,due_date,payment_date,invoice_amount,payment_amount,contract_start,contract_end,deal_type
LC2024001,OpenAI,2024-03-15,2024-04-14,2024-04-10,50000,50000,2024-01-01,2024-12-31,fixed_annual
LC2024002,Anthropic,2024-03-20,2024-04-19,2024-04-25,75000,75000,2024-02-01,2027-01-31,fixed_annual
LC2024003,Cohere,2024-04-01,2024-05-01,,12500,0,2024-04-01,2025-03-31,consumption_based
</code></pre>
<p><strong>Web analytics integration</strong> pulls traffic data from Google Analytics, Adobe Analytics, or Matomo. Required metrics:</p>
<ul>
<li><strong>Total pageviews by source</strong> — organic search, direct, referral, social</li>
<li><strong>Pageviews by content type</strong> — articles, guides, documentation</li>
<li><strong>Time-series data</strong> — daily or weekly granularity for trend analysis</li>
<li><strong>Session engagement</strong> — time on page, bounce rate as quality indicators</li>
</ul>
<p>Export via analytics platform APIs. Google Analytics Data API example:</p>
<pre><code class="language-python">from google.analytics.data_v1beta import BetaAnalyticsDataClient
from google.analytics.data_v1beta.types import RunReportRequest, DateRange, Metric, Dimension

def export_traffic_data(property_id, start_date, end_date):
    client = BetaAnalyticsDataClient()

    request = RunReportRequest(
        property=f&quot;properties/{property_id}&quot;,
        date_ranges=[DateRange(start_date=start_date, end_date=end_date)],
        dimensions=[
            Dimension(name=&quot;date&quot;),
            Dimension(name=&quot;sessionDefaultChannelGroup&quot;)
        ],
        metrics=[
            Metric(name=&quot;screenPageViews&quot;),
            Metric(name=&quot;sessions&quot;),
            Metric(name=&quot;engagementRate&quot;)
        ]
    )

    response = client.run_report(request)

    # Convert to CSV format
    rows = []
    for row in response.rows:
        rows.append({
            &#39;date&#39;: row.dimension_values[0].value,
            &#39;channel&#39;: row.dimension_values[1].value,
            &#39;pageviews&#39;: row.metric_values[0].value,
            &#39;sessions&#39;: row.metric_values[1].value,
            &#39;engagement_rate&#39;: row.metric_values[2].value
        })

    return rows
</code></pre>
<p>Run this export weekly, store results in CSV or database for dashboard consumption.</p>
<p><strong>Server infrastructure data</strong> comes from <a href="prometheus-grafana-ai-crawler-metrics.html">web server access logs</a> parsed for AI crawler activity. Key metrics:</p>
<ul>
<li><strong>Request volume per crawler</strong> — total requests by GPTBot, ClaudeBot, etc.</li>
<li><strong>Bandwidth consumption per crawler</strong> — bytes transferred</li>
<li><strong>Content targeting patterns</strong> — which site sections crawlers access most</li>
<li><strong>Robots.txt violations</strong> — attempts to access blocked resources</li>
</ul>
<p>Parse logs using existing monitoring infrastructure or standalone scripts:</p>
<pre><code class="language-python">import re
from collections import defaultdict
from datetime import datetime

AI_CRAWLERS = {
    &#39;OpenAI&#39;: r&#39;GPTBot&#39;,
    &#39;Anthropic&#39;: r&#39;ClaudeBot&#39;,
    &#39;Google&#39;: r&#39;Google-Extended&#39;,
    &#39;CommonCrawl&#39;: r&#39;CCBot&#39;,
    &#39;Cohere&#39;: r&#39;cohere-ai&#39;
}

def parse_crawler_activity(log_file, start_date, end_date):
    activity = defaultdict(lambda: {&#39;requests&#39;: 0, &#39;bandwidth&#39;: 0})

    with open(log_file, &#39;r&#39;) as f:
        for line in f:
            match = re.search(r&#39;\[(\d{2}/\w{3}/\d{4}:\d{2}:\d{2}:\d{2})&#39;, line)
            if not match:
                continue

            log_date = datetime.strptime(match.group(1), &#39;%d/%b/%Y:%H:%M:%S&#39;)
            if not (start_date &lt;= log_date &lt;= end_date):
                continue

            for company, pattern in AI_CRAWLERS.items():
                if re.search(pattern, line):
                    bytes_match = re.search(r&#39;&quot;\s+\d{3}\s+(\d+)\s+&quot;&#39;, line)
                    if bytes_match:
                        activity[company][&#39;requests&#39;] += 1
                        activity[company][&#39;bandwidth&#39;] += int(bytes_match.group(1))

    return activity
</code></pre>
<p>Run weekly alongside financial and analytics exports.</p>
<p><strong>Business intelligence data</strong> tracks licensing deal pipeline and negotiation progress. Source from CRM (Salesforce, HubSpot) or manual spreadsheet tracking:</p>
<ul>
<li><strong>Prospect company</strong> — AI companies in outreach pipeline</li>
<li><strong>Deal stage</strong> — initial contact, proposal sent, negotiation, legal review, signed</li>
<li><strong>Estimated value</strong> — projected annual revenue from deal</li>
<li><strong>Probability</strong> — weighted likelihood of closing (e.g., 25% at proposal stage, 75% at legal review)</li>
<li><strong>Expected close date</strong> — projected contract signature date</li>
<li><strong>Key contact</strong> — business development lead at AI company</li>
</ul>
<p>Structure pipeline export:</p>
<pre><code>prospect_id,ai_company,deal_stage,estimated_value,probability,expected_close_date,last_contact_date
PIP001,Perplexity,negotiation,80000,0.50,2026-05-15,2026-02-01
PIP002,Cohere,legal_review,120000,0.75,2026-03-30,2026-02-05
PIP003,Meta,initial_contact,200000,0.10,2026-08-01,2026-01-15
</code></pre>
<p>Update pipeline data weekly as deal stages evolve.</p>
<h2>Google Sheets Implementation: Accessible Executive Dashboard</h2>
<p><strong>Google Sheets</strong> provides rapid deployment for publishers lacking dedicated engineering resources. This approach requires no coding infrastructure, updates via manual CSV imports or Google Analytics add-ons, and renders in familiar spreadsheet interfaces executives already use.</p>
<p><strong>Dashboard structure</strong> uses five connected sheets:</p>
<ol>
<li><strong>Revenue Summary</strong> — executive overview with key metrics</li>
<li><strong>Financial Data</strong> — imported payment records</li>
<li><strong>Traffic Data</strong> — imported analytics</li>
<li><strong>Crawler Activity</strong> — imported server logs</li>
<li><strong>Pipeline Tracker</strong> — deal negotiation status</li>
</ol>
<h3>Sheet 1: Revenue Summary (Executive View)</h3>
<p>Create executive summary displaying:</p>
<p><strong>Key Metrics Section</strong> (auto-calculated from other sheets):</p>
<ul>
<li>Total AI Licensing Revenue (TTM) — trailing twelve months</li>
<li>Current Month Revenue</li>
<li>Revenue Growth Rate (MoM)</li>
<li>Active Partnerships Count</li>
<li>Pipeline Value (weighted)</li>
</ul>
<p>Implement using formulas referencing Financial Data sheet:</p>
<pre><code>Total AI Revenue (TTM):
=SUMIFS(&#39;Financial Data&#39;!F:F, &#39;Financial Data&#39;!C:C, &quot;&gt;=&quot;&amp;TODAY()-365, &#39;Financial Data&#39;!G:G, &quot;&lt;&gt;0&quot;)

Current Month Revenue:
=SUMIFS(&#39;Financial Data&#39;!F:F, &#39;Financial Data&#39;!C:C, &quot;&gt;=&quot;&amp;DATE(YEAR(TODAY()),MONTH(TODAY()),1), &#39;Financial Data&#39;!G:G, &quot;&lt;&gt;0&quot;)

Revenue Growth Rate:
=(Current_Month_Revenue - Prior_Month_Revenue) / Prior_Month_Revenue
</code></pre>
<p><strong>Revenue by Partner</strong> (horizontal bar chart):
Pull from Financial Data sheet, group by <code>ai_company</code>, sum <code>payment_amount</code> where <code>payment_date</code> is not null.</p>
<p>Create data range:</p>
<pre><code>AI Company | TTM Revenue
OpenAI     | =SUMIFS(&#39;Financial Data&#39;!G:G, &#39;Financial Data&#39;!B:B, &quot;OpenAI&quot;, &#39;Financial Data&#39;!C:C, &quot;&gt;=&quot;&amp;TODAY()-365)
Anthropic  | =SUMIFS(&#39;Financial Data&#39;!G:G, &#39;Financial Data&#39;!B:B, &quot;Anthropic&quot;, &#39;Financial Data&#39;!C:C, &quot;&gt;=&quot;&amp;TODAY()-365)
Google     | =SUMIFS(&#39;Financial Data&#39;!G:G, &#39;Financial Data&#39;!B:B, &quot;Google&quot;, &#39;Financial Data&#39;!C:C, &quot;&gt;=&quot;&amp;TODAY()-365)
</code></pre>
<p>Insert chart: Insert → Chart → Bar chart, select data range above.</p>
<p><strong>Traffic Impact Visualization</strong> (line chart with dual axes):</p>
<ul>
<li>Primary axis: Total monthly pageviews (from Traffic Data sheet)</li>
<li>Secondary axis: AI crawler requests (from Crawler Activity sheet)</li>
</ul>
<p>Create monthly aggregation:</p>
<pre><code>Month       | Total Pageviews | AI Requests
2025-08     | =SUMIFS(&#39;Traffic Data&#39;!C:C, &#39;Traffic Data&#39;!A:A, &quot;&gt;=2025-08-01&quot;, &#39;Traffic Data&#39;!A:A, &quot;&lt;2025-09-01&quot;)
2025-09     | =SUMIFS(&#39;Traffic Data&#39;!C:C, &#39;Traffic Data&#39;!A:A, &quot;&gt;=2025-09-01&quot;, &#39;Traffic Data&#39;!A:A, &quot;&lt;2025-10-01&quot;)
</code></pre>
<p>Insert combo chart showing traffic trends alongside crawler activity.</p>
<p><strong>Net Profitability Analysis</strong>:
Revenue minus attributed costs:</p>
<pre><code>Gross Revenue: [Sum of all payments received]
- Infrastructure Costs: [Bandwidth costs from crawler activity × $0.09/GB]
- Legal Fees: [Sum of legal review costs per deal]
- Staff Time: [Hours spent × hourly rate]
= Net Profit from AI Licensing
</code></pre>
<p>Calculate ROI:</p>
<pre><code>ROI = (Net Profit / Total Costs) × 100%
</code></pre>
<p>Display in prominent cells with conditional formatting (green if &gt;200% ROI, yellow 50-200%, red &lt;50%).</p>
<h3>Sheet 2: Financial Data Import</h3>
<p>Manual CSV import process:</p>
<ol>
<li>Export invoice/payment data from accounting software monthly</li>
<li>Google Sheets: File → Import → Upload CSV</li>
<li>Select &quot;Replace current sheet&quot; for Financial Data tab</li>
<li>Verify column mappings match expected structure</li>
</ol>
<p>Automate using Google Apps Script for advanced users:</p>
<pre><code class="language-javascript">function importFinancialData() {
  var sheet = SpreadsheetApp.getActiveSpreadsheet().getSheetByName(&#39;Financial Data&#39;);
  var csvUrl = &#39;https://your-accounting-software.com/export/invoices.csv&#39;;

  var response = UrlFetchApp.fetch(csvUrl, {
    headers: { &#39;Authorization&#39;: &#39;Bearer YOUR_API_TOKEN&#39; }
  });

  var csvData = Utilities.parseCsv(response.getContentText());
  sheet.getRange(2, 1, csvData.length, csvData[0].length).setValues(csvData);
}
</code></pre>
<p>Set trigger to run monthly: Edit → Current project&#39;s triggers → Add trigger → <code>importFinancialData</code>, Time-driven, Month timer.</p>
<h3>Sheet 3: Traffic Data Import</h3>
<p>Connect Google Analytics directly using Google Analytics add-on:</p>
<ol>
<li>Extensions → Add-ons → Get add-ons → Search &quot;Google Analytics&quot;</li>
<li>Install official Google Analytics add-on</li>
<li>Add-ons → Google Analytics → Create new report</li>
<li>Configure report:<ul>
<li>Metrics: ga:pageviews, ga:sessions</li>
<li>Dimensions: ga:date, ga:channelGrouping</li>
<li>Segment: All Users</li>
<li>Date range: Last 90 days</li>
</ul>
</li>
<li>Run report → data populates in new sheet</li>
<li>Rename sheet to &quot;Traffic Data&quot;</li>
</ol>
<p>Schedule automatic refresh: Report Configuration → Enable reports to run automatically (daily).</p>
<h3>Sheet 4: Crawler Activity Import</h3>
<p>Manual CSV import from server log analysis:</p>
<ol>
<li>Run weekly log parsing script (provided earlier) outputting CSV</li>
<li>Import CSV into &quot;Crawler Activity&quot; sheet</li>
<li>Aggregate data by week for cleaner visualization</li>
</ol>
<p>Formula to calculate weekly totals:</p>
<pre><code>Week Starting | Crawler      | Requests | Bandwidth GB
=DATE(...)    | OpenAI       | =SUM()   | =SUM()/1e9
</code></pre>
<h3>Sheet 5: Pipeline Tracker</h3>
<p>Manual entry tracking ongoing negotiations:</p>
<p>Columns:</p>
<ul>
<li>Company</li>
<li>Stage (dropdown: Contact, Proposal, Negotiation, Legal, Signed)</li>
<li>Estimated Value</li>
<li>Probability (dropdown: 10%, 25%, 50%, 75%, 90%)</li>
<li>Weighted Value (formula: =Estimated_Value × Probability)</li>
<li>Expected Close Date</li>
<li>Days to Close (formula: =Expected_Close_Date - TODAY())</li>
<li>Last Activity Date</li>
<li>Next Action</li>
</ul>
<p>Calculate total pipeline value:</p>
<pre><code>Weighted Pipeline Value = SUM(Weighted_Value column)
</code></pre>
<p>Display in Revenue Summary sheet with breakdown by stage.</p>
<p><strong>Dashboard refresh cadence</strong>:</p>
<ul>
<li>Financial Data: Monthly (after invoicing cycle)</li>
<li>Traffic Data: Daily (automated via GA add-on)</li>
<li>Crawler Activity: Weekly (manual CSV import)</li>
<li>Pipeline Tracker: Weekly (manual updates)</li>
</ul>
<h2>Grafana + PostgreSQL Implementation: Enterprise Dashboard</h2>
<p><strong>Enterprise publishers</strong> with engineering resources benefit from automated, real-time dashboards using Grafana visualization platform backed by PostgreSQL database.</p>
<p><strong>Architecture overview</strong>:</p>
<ul>
<li>PostgreSQL database stores all metrics (financial, traffic, crawler, pipeline)</li>
<li>ETL scripts extract data from source systems, transform, load into PostgreSQL</li>
<li>Grafana connects to PostgreSQL, builds dashboards via SQL queries</li>
<li>Automated refresh: ETL runs hourly/daily via cron, Grafana queries database in real-time</li>
</ul>
<h3>Database Schema Design</h3>
<p>Create PostgreSQL database with four core tables:</p>
<pre><code class="language-sql">-- Financial transactions
CREATE TABLE ai_licensing_revenue (
    id SERIAL PRIMARY KEY,
    deal_id VARCHAR(50) UNIQUE NOT NULL,
    ai_company VARCHAR(100) NOT NULL,
    invoice_date DATE NOT NULL,
    due_date DATE NOT NULL,
    payment_date DATE,
    invoice_amount NUMERIC(10,2) NOT NULL,
    payment_amount NUMERIC(10,2),
    contract_start DATE NOT NULL,
    contract_end DATE NOT NULL,
    deal_type VARCHAR(50) NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Website traffic metrics
CREATE TABLE traffic_metrics (
    id SERIAL PRIMARY KEY,
    date DATE NOT NULL,
    channel VARCHAR(50) NOT NULL,
    pageviews INTEGER NOT NULL,
    sessions INTEGER NOT NULL,
    engagement_rate NUMERIC(5,4),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(date, channel)
);

-- AI crawler activity
CREATE TABLE crawler_activity (
    id SERIAL PRIMARY KEY,
    date DATE NOT NULL,
    ai_company VARCHAR(100) NOT NULL,
    requests INTEGER NOT NULL,
    bandwidth_bytes BIGINT NOT NULL,
    unique_paths INTEGER,
    avg_response_time_ms INTEGER,
    robots_violations INTEGER DEFAULT 0,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(date, ai_company)
);

-- Deal pipeline
CREATE TABLE deal_pipeline (
    id SERIAL PRIMARY KEY,
    prospect_id VARCHAR(50) UNIQUE NOT NULL,
    ai_company VARCHAR(100) NOT NULL,
    deal_stage VARCHAR(50) NOT NULL,
    estimated_value NUMERIC(10,2) NOT NULL,
    probability NUMERIC(3,2) NOT NULL,
    expected_close_date DATE,
    last_contact_date DATE,
    notes TEXT,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
</code></pre>
<p>Create indexes for query performance:</p>
<pre><code class="language-sql">CREATE INDEX idx_revenue_company ON ai_licensing_revenue(ai_company);
CREATE INDEX idx_revenue_payment_date ON ai_licensing_revenue(payment_date);
CREATE INDEX idx_traffic_date ON traffic_metrics(date);
CREATE INDEX idx_crawler_date_company ON crawler_activity(date, ai_company);
CREATE INDEX idx_pipeline_stage ON deal_pipeline(deal_stage);
</code></pre>
<h3>ETL Pipeline Implementation</h3>
<p><strong>Financial data ETL</strong> (Python script scheduled via cron):</p>
<pre><code class="language-python">import psycopg2
import csv
from datetime import datetime

def load_financial_data(csv_file_path, db_connection):
    with open(csv_file_path, &#39;r&#39;) as f:
        reader = csv.DictReader(f)

        cursor = db_connection.cursor()

        for row in reader:
            cursor.execute(&quot;&quot;&quot;
                INSERT INTO ai_licensing_revenue
                (deal_id, ai_company, invoice_date, due_date, payment_date,
                 invoice_amount, payment_amount, contract_start, contract_end, deal_type)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                ON CONFLICT (deal_id) DO UPDATE SET
                    payment_date = EXCLUDED.payment_date,
                    payment_amount = EXCLUDED.payment_amount,
                    updated_at = CURRENT_TIMESTAMP
            &quot;&quot;&quot;, (
                row[&#39;deal_id&#39;], row[&#39;ai_company&#39;],
                row[&#39;invoice_date&#39;], row[&#39;due_date&#39;],
                row[&#39;payment_date&#39;] if row[&#39;payment_date&#39;] else None,
                float(row[&#39;invoice_amount&#39;]),
                float(row[&#39;payment_amount&#39;]) if row[&#39;payment_amount&#39;] else None,
                row[&#39;contract_start&#39;], row[&#39;contract_end&#39;], row[&#39;deal_type&#39;]
            ))

        db_connection.commit()
        cursor.close()

# Run daily
conn = psycopg2.connect(&quot;dbname=ai_revenue user=postgres password=xxx host=localhost&quot;)
load_financial_data(&#39;/data/exports/invoices.csv&#39;, conn)
conn.close()
</code></pre>
<p><strong>Traffic data ETL</strong> (using Google Analytics Data API):</p>
<pre><code class="language-python">from google.analytics.data_v1beta import BetaAnalyticsDataClient
import psycopg2

def load_traffic_data(property_id, db_connection, days_back=7):
    client = BetaAnalyticsDataClient()

    # Fetch last 7 days of traffic data
    request = RunReportRequest(
        property=f&quot;properties/{property_id}&quot;,
        date_ranges=[DateRange(
            start_date=f&quot;{days_back}daysAgo&quot;,
            end_date=&quot;today&quot;
        )],
        dimensions=[Dimension(name=&quot;date&quot;), Dimension(name=&quot;sessionDefaultChannelGroup&quot;)],
        metrics=[Metric(name=&quot;screenPageViews&quot;), Metric(name=&quot;sessions&quot;), Metric(name=&quot;engagementRate&quot;)]
    )

    response = client.run_report(request)

    cursor = db_connection.cursor()

    for row in response.rows:
        cursor.execute(&quot;&quot;&quot;
            INSERT INTO traffic_metrics (date, channel, pageviews, sessions, engagement_rate)
            VALUES (%s, %s, %s, %s, %s)
            ON CONFLICT (date, channel) DO UPDATE SET
                pageviews = EXCLUDED.pageviews,
                sessions = EXCLUDED.sessions,
                engagement_rate = EXCLUDED.engagement_rate
        &quot;&quot;&quot;, (
            row.dimension_values[0].value,
            row.dimension_values[1].value,
            int(row.metric_values[0].value),
            int(row.metric_values[1].value),
            float(row.metric_values[2].value)
        ))

    db_connection.commit()
    cursor.close()

# Run daily
conn = psycopg2.connect(&quot;dbname=ai_revenue user=postgres password=xxx host=localhost&quot;)
load_traffic_data(&#39;YOUR_GA4_PROPERTY_ID&#39;, conn)
conn.close()
</code></pre>
<p><strong>Crawler activity ETL</strong>:</p>
<pre><code class="language-python">import psycopg2
from datetime import datetime, timedelta

def load_crawler_activity(log_analysis_results, db_connection):
    &quot;&quot;&quot;
    log_analysis_results: dict from parse_crawler_activity() function
    &quot;&quot;&quot;

    cursor = db_connection.cursor()

    for ai_company, data in log_analysis_results.items():
        cursor.execute(&quot;&quot;&quot;
            INSERT INTO crawler_activity
            (date, ai_company, requests, bandwidth_bytes, robots_violations)
            VALUES (%s, %s, %s, %s, %s)
            ON CONFLICT (date, ai_company) DO UPDATE SET
                requests = crawler_activity.requests + EXCLUDED.requests,
                bandwidth_bytes = crawler_activity.bandwidth_bytes + EXCLUDED.bandwidth_bytes,
                robots_violations = crawler_activity.robots_violations + EXCLUDED.robots_violations
        &quot;&quot;&quot;, (
            datetime.now().date(),
            ai_company,
            data[&#39;requests&#39;],
            data[&#39;bandwidth&#39;],
            data.get(&#39;violations&#39;, 0)
        ))

    db_connection.commit()
    cursor.close()

# Run daily from cron after log analysis
activity_data = parse_crawler_activity(&#39;/var/log/nginx/access.log&#39;, datetime.now() - timedelta(days=1), datetime.now())
conn = psycopg2.connect(&quot;dbname=ai_revenue user=postgres password=xxx host=localhost&quot;)
load_crawler_activity(activity_data, conn)
conn.close()
</code></pre>
<p>Schedule all ETL scripts via crontab:</p>
<pre><code># Financial data ETL - daily at 2am
0 2 * * * /usr/bin/python3 /opt/etl/load_financial_data.py

# Traffic data ETL - daily at 3am
0 3 * * * /usr/bin/python3 /opt/etl/load_traffic_data.py

# Crawler activity ETL - daily at 4am
0 4 * * * /usr/bin/python3 /opt/etl/load_crawler_activity.py
</code></pre>
<h3>Grafana Dashboard Configuration</h3>
<p>Install Grafana and configure PostgreSQL data source:</p>
<pre><code class="language-bash"># Install Grafana
sudo apt-get install -y adduser libfontconfig1
wget https://dl.grafana.com/oss/release/grafana_10.0.0_amd64.deb
sudo dpkg -i grafana_10.0.0_amd64.deb
sudo systemctl start grafana-server
</code></pre>
<p>Access Grafana at <code>http://localhost:3000</code>, add PostgreSQL data source:</p>
<p>Configuration → Data Sources → Add data source → PostgreSQL</p>
<p>Settings:</p>
<ul>
<li>Host: <code>localhost:5432</code></li>
<li>Database: <code>ai_revenue</code></li>
<li>User: <code>postgres</code></li>
<li>Password: <code>[your password]</code></li>
<li>SSL Mode: <code>disable</code> (or configure SSL)</li>
</ul>
<p><strong>Create Executive Dashboard</strong> with eight panels:</p>
<p><strong>Panel 1: Total AI Revenue (Stat)</strong></p>
<p>Query:</p>
<pre><code class="language-sql">SELECT SUM(payment_amount) as total_revenue
FROM ai_licensing_revenue
WHERE payment_date &gt;= CURRENT_DATE - INTERVAL &#39;12 months&#39;
  AND payment_amount IS NOT NULL
</code></pre>
<p>Visualization: Stat panel
Format: Currency ($)
Title: &quot;AI Licensing Revenue (TTM)&quot;</p>
<p><strong>Panel 2: Revenue by Partner (Bar Gauge)</strong></p>
<p>Query:</p>
<pre><code class="language-sql">SELECT
    ai_company,
    SUM(payment_amount) as revenue
FROM ai_licensing_revenue
WHERE payment_date &gt;= CURRENT_DATE - INTERVAL &#39;12 months&#39;
  AND payment_amount IS NOT NULL
GROUP BY ai_company
ORDER BY revenue DESC
</code></pre>
<p>Visualization: Bar gauge (horizontal)
Format: Currency ($)</p>
<p><strong>Panel 3: Monthly Revenue Trend (Time Series)</strong></p>
<p>Query:</p>
<pre><code class="language-sql">SELECT
    DATE_TRUNC(&#39;month&#39;, payment_date) as month,
    SUM(payment_amount) as monthly_revenue
FROM ai_licensing_revenue
WHERE payment_date &gt;= CURRENT_DATE - INTERVAL &#39;24 months&#39;
  AND payment_amount IS NOT NULL
GROUP BY month
ORDER BY month
</code></pre>
<p>Visualization: Time series line chart
X-axis: month
Y-axis: monthly_revenue (currency format)</p>
<p><strong>Panel 4: Traffic vs AI Crawler Activity (Dual-axis Time Series)</strong></p>
<p>Query:</p>
<pre><code class="language-sql">SELECT
    t.date as time,
    SUM(t.pageviews) as total_pageviews,
    SUM(c.requests) as crawler_requests
FROM traffic_metrics t
LEFT JOIN crawler_activity c ON t.date = c.date
WHERE t.date &gt;= CURRENT_DATE - INTERVAL &#39;90 days&#39;
GROUP BY t.date
ORDER BY t.date
</code></pre>
<p>Visualization: Time series with two Y-axes
Left axis: total_pageviews
Right axis: crawler_requests</p>
<p><strong>Panel 5: Crawler Bandwidth Consumption (Pie Chart)</strong></p>
<p>Query:</p>
<pre><code class="language-sql">SELECT
    ai_company,
    SUM(bandwidth_bytes) / 1e9 as bandwidth_gb
FROM crawler_activity
WHERE date &gt;= CURRENT_DATE - INTERVAL &#39;30 days&#39;
GROUP BY ai_company
</code></pre>
<p>Visualization: Pie chart
Format: Gigabytes (GB)</p>
<p><strong>Panel 6: Deal Pipeline Value (Table)</strong></p>
<p>Query:</p>
<pre><code class="language-sql">SELECT
    ai_company,
    deal_stage,
    estimated_value,
    probability,
    estimated_value * probability as weighted_value,
    expected_close_date
FROM deal_pipeline
WHERE deal_stage != &#39;Signed&#39;
ORDER BY weighted_value DESC
</code></pre>
<p>Visualization: Table
Columns: Company, Stage, Est. Value, Probability, Weighted Value, Expected Close</p>
<p><strong>Panel 7: Net Profitability (Stat with Sparkline)</strong></p>
<p>Query:</p>
<pre><code class="language-sql">SELECT
    (SELECT SUM(payment_amount) FROM ai_licensing_revenue
     WHERE payment_date &gt;= CURRENT_DATE - INTERVAL &#39;12 months&#39;) as revenue,
    (SELECT SUM(bandwidth_bytes) * 0.09 / 1e9 FROM crawler_activity
     WHERE date &gt;= CURRENT_DATE - INTERVAL &#39;12 months&#39;) as bandwidth_cost,
    -- Add legal fees and staff costs from separate cost tracking table if available
    (SELECT SUM(payment_amount) FROM ai_licensing_revenue
     WHERE payment_date &gt;= CURRENT_DATE - INTERVAL &#39;12 months&#39;) -
    (SELECT SUM(bandwidth_bytes) * 0.09 / 1e9 FROM crawler_activity
     WHERE date &gt;= CURRENT_DATE - INTERVAL &#39;12 months&#39;) as net_profit
</code></pre>
<p>Visualization: Stat panel with sparkline
Format: Currency ($)
Title: &quot;Net AI Licensing Profit (TTM)&quot;</p>
<p><strong>Panel 8: Payment Status (Table)</strong></p>
<p>Query:</p>
<pre><code class="language-sql">SELECT
    ai_company,
    invoice_date,
    due_date,
    payment_date,
    invoice_amount,
    payment_amount,
    CASE
        WHEN payment_date IS NULL AND due_date &lt; CURRENT_DATE THEN &#39;OVERDUE&#39;
        WHEN payment_date IS NULL THEN &#39;PENDING&#39;
        WHEN payment_date &lt;= due_date THEN &#39;ON TIME&#39;
        ELSE &#39;LATE&#39;
    END as status
FROM ai_licensing_revenue
WHERE invoice_date &gt;= CURRENT_DATE - INTERVAL &#39;6 months&#39;
ORDER BY invoice_date DESC
</code></pre>
<p>Visualization: Table
Conditional formatting: Red row for OVERDUE, yellow for PENDING, green for ON TIME</p>
<p>Configure dashboard refresh: Dashboard settings → Auto refresh → 5 minutes</p>
<p>This configuration provides real-time executive visibility into AI licensing financial performance, integrating data from accounting, analytics, and infrastructure systems into unified metrics.</p>
<p>Publishers operating mature AI licensing programs use these dashboards for quarterly board presentations, investor updates, and internal performance reviews demonstrating AI monetization as a growing revenue line alongside traditional advertising and subscription income.</p>

      </article>

      <div class="cta-box" style="margin: var(--sp-16) 0;">
        <h3>Your Content Feeds AI. Get Paid for It.</h3>
        <p>Complete pay-per-crawl implementation. Templates, pricing models, licensing contracts. Everything.</p>
        <a href="/setup.html" class="btn btn--primary btn--large">Master the Protocol &mdash; $2,497</a>
      </div>

      <div style="margin-top: var(--sp-8); padding-top: var(--sp-8); border-top: 1px solid var(--border);">
        <a href="/articles.html" style="font-family: var(--font-mono); font-size: 0.875rem; font-weight: 500; color: var(--accent);">&larr; All Articles</a>
      </div>
    </div>
  </main>


  <footer class="footer">
    <div class="container">
      <div class="footer__grid">
        <div class="footer__brand">
          <div class="footer__logo">AI Pay Per Crawl</div>
          <p class="footer__desc">Your content feeds AI. The protocol ensures you get paid for it. Implementation guides, pricing models, and licensing infrastructure for publishers monetizing AI crawler traffic.</p>
          <a href="/setup.html" class="btn btn--primary" style="font-size: 0.8125rem; padding: 0.625rem 1.25rem;">Get Rule &mdash; $2,497</a>
        </div>

        <div>
          <div class="footer__heading">Implementation</div>
          <ul class="footer__links">
            <li><a href="/articles.html">Cloudflare Setup</a></li>
            <li><a href="/articles.html">RSL Protocol</a></li>
            <li><a href="/articles.html">llms.txt Guide</a></li>
            <li><a href="/articles.html">Nginx Rules</a></li>
            <li><a href="/articles.html">Apache Config</a></li>
            <li><a href="/articles.html">WordPress Plugin</a></li>
            <li><a href="/articles.html">CDN Integration</a></li>
            <li><a href="/articles.html">robots.txt Templates</a></li>
          </ul>
        </div>

        <div>
          <div class="footer__heading">Pricing &amp; Tools</div>
          <ul class="footer__links">
            <li><a href="/articles.html">Pricing Models</a></li>
            <li><a href="/articles.html">Rate Cards</a></li>
            <li><a href="/articles.html">Revenue Calculator</a></li>
            <li><a href="/articles.html">Crawler Directory</a></li>
            <li><a href="/articles.html">Bot Detection</a></li>
            <li><a href="/articles.html">Compliance Rates</a></li>
            <li><a href="/articles.html">Deal Analysis</a></li>
            <li><a href="/articles.html">Licensing Templates</a></li>
          </ul>
        </div>

        <div>
          <div class="footer__heading">From Scale With Search</div>
          <ul class="footer__links">
            <li><a href="https://scalewithsearch.com" target="_blank" rel="me">Scale With Search</a></li>
            <li><a href="https://aifirstsearch.com" target="_blank" rel="me">AI First Search</a></li>
            <li><a href="https://browserprompt.com" target="_blank" rel="me">Browser Prompt</a></li>
            <li><a href="https://polytraffic.com" target="_blank" rel="me">Polytraffic</a></li>
            <li><a href="https://creatinepedia.com" target="_blank" rel="me">Creatinepedia</a></li>
            <li><a href="https://victorvalentineromo.com" target="_blank" rel="me">Victor Romo</a></li>
            <li><a href="https://b2bvic.com" target="_blank" rel="me">B2B Vic</a></li>
          </ul>
        </div>
      </div>

      <div class="footer__bar">
        <p>&copy; 2026 AI Pay Per Crawl. Built by <a href="https://victorvalentineromo.com" target="_blank">Victor Valentine Romo</a>.</p>
        <p>A <a href="https://scalewithsearch.com" target="_blank">Scale With Search</a> property.</p>
      </div>
    </div>
  </footer>


  <script>
    /* Mega menu */
    (function() {
      var triggers = document.querySelectorAll('.mega-trigger');
      var panels = document.querySelectorAll('.mega-panel');
      var closeTimeout = null;

      function openPanel(id) {
        clearTimeout(closeTimeout);
        panels.forEach(function(p) { p.classList.remove('mega-panel--open'); });
        triggers.forEach(function(t) { t.setAttribute('aria-expanded', 'false'); });
        var panel = document.getElementById('mega-' + id);
        var trigger = document.querySelector('[data-mega="' + id + '"] .mega-trigger');
        if (panel) panel.classList.add('mega-panel--open');
        if (trigger) trigger.setAttribute('aria-expanded', 'true');
      }

      function scheduleClose() {
        closeTimeout = setTimeout(function() {
          panels.forEach(function(p) { p.classList.remove('mega-panel--open'); });
          triggers.forEach(function(t) { t.setAttribute('aria-expanded', 'false'); });
        }, 200);
      }

      function cancelClose() { clearTimeout(closeTimeout); }

      triggers.forEach(function(btn) {
        var wrapper = btn.closest('[data-mega]');
        var id = wrapper.getAttribute('data-mega');
        btn.addEventListener('mouseenter', function() { openPanel(id); });
        btn.addEventListener('click', function(e) {
          e.preventDefault();
          var panel = document.getElementById('mega-' + id);
          if (panel && panel.classList.contains('mega-panel--open')) {
            panel.classList.remove('mega-panel--open');
            btn.setAttribute('aria-expanded', 'false');
          } else {
            openPanel(id);
          }
        });
        wrapper.addEventListener('mouseleave', scheduleClose);
      });

      panels.forEach(function(panel) {
        panel.addEventListener('mouseenter', cancelClose);
        panel.addEventListener('mouseleave', scheduleClose);
      });

      document.addEventListener('click', function(e) {
        if (!e.target.closest('[data-mega]') && !e.target.closest('.mega-panel')) {
          panels.forEach(function(p) { p.classList.remove('mega-panel--open'); });
          triggers.forEach(function(t) { t.setAttribute('aria-expanded', 'false'); });
        }
      });

      document.addEventListener('keydown', function(e) {
        if (e.key === 'Escape') {
          panels.forEach(function(p) { p.classList.remove('mega-panel--open'); });
          triggers.forEach(function(t) { t.setAttribute('aria-expanded', 'false'); });
        }
      });
    })();

    /* Mobile menu */
    var mobileMenuBtn = document.getElementById('mobile-menu-btn');
    var mobileMenu = document.getElementById('mobile-menu');
    var menuIcon = document.getElementById('menu-icon');
    var closeIcon = document.getElementById('close-icon');
    if (mobileMenuBtn) {
      mobileMenuBtn.addEventListener('click', function() {
        mobileMenu.classList.toggle('mobile-menu--open');
        menuIcon.classList.toggle('hidden');
        closeIcon.classList.toggle('hidden');
      });
    }

    /* Self-link neutralizer */
    (function() {
      var currentPath = window.location.pathname.replace(/\.html$/, '').replace(/\/$/, '') || '/';
      document.querySelectorAll('a[href]').forEach(function(a) {
        var href = a.getAttribute('href').replace(/\.html$/, '').replace(/\/$/, '') || '/';
        if (href === currentPath) {
          a.removeAttribute('href');
          a.setAttribute('aria-current', 'page');
          a.style.opacity = '0.5';
          a.style.pointerEvents = 'none';
        }
      });
    })();

    /* Copy code button */
    function copyCode(button) {
      var codeBlock = button.closest('.code-block');
      var code = codeBlock.querySelector('code').innerText;
      navigator.clipboard.writeText(code).then(function() {
        button.textContent = 'Copied!';
        setTimeout(function() { button.textContent = 'Copy'; }, 2000);
      });
    }

    /* FAQ Accordion */
    document.querySelectorAll('.accordion__trigger').forEach(function(trigger) {
      trigger.addEventListener('click', function() {
        var expanded = this.getAttribute('aria-expanded') === 'true';
        var body = this.nextElementSibling;
        this.setAttribute('aria-expanded', !expanded);
        body.classList.toggle('accordion__body--open');
      });
    });
  </script>
</body>
</html>