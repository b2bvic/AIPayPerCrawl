<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ai crawler user agent strings | AI Pay Per Crawl</title>
    <meta name="description" content="">
    <meta name="author" content="Victor Valentine Romo">
    <meta name="robots" content="index, follow">
    <meta property="og:title" content="ai crawler user agent strings">
    <meta property="og:description" content="">
    <meta property="og:type" content="article">
    <meta property="og:url" content="https://aipaypercrawl.com/articles/ai-crawler-user-agent-strings">
    <meta property="og:site_name" content="AI Pay Per Crawl">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="ai crawler user agent strings">
    <meta name="twitter:description" content="">
    <link rel="canonical" href="https://aipaypercrawl.com/articles/ai-crawler-user-agent-strings">
    <script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "TechArticle",
  "headline": "ai crawler user agent strings",
  "description": "",
  "author": {
    "@type": "Person",
    "@id": "https://victorvalentineromo.com/#person",
    "name": "Victor Valentine Romo",
    "url": "https://victorvalentineromo.com"
  },
  "publisher": {
    "@type": "Organization",
    "@id": "https://aipaypercrawl.com/#organization",
    "name": "AI Pay Per Crawl",
    "url": "https://aipaypercrawl.com"
  },
  "datePublished": "2026-01-19",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://aipaypercrawl.com/articles/ai-crawler-user-agent-strings"
  }
}
    </script>
    <script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position": 1,
      "name": "Home",
      "item": "https://aipaypercrawl.com"
    },
    {
      "@type": "ListItem",
      "position": 2,
      "name": "Articles",
      "item": "https://aipaypercrawl.com/articles.html"
    },
    {
      "@type": "ListItem",
      "position": 3,
      "name": "ai crawler user agent strings",
      "item": "https://aipaypercrawl.com/articles/ai-crawler-user-agent-strings"
    }
  ]
}
    </script>

    <link rel="icon" type="image/svg+xml" href="data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 100 100'><rect fill='%234f46e5' width='100' height='100' rx='12'/><text x='50' y='70' font-family='monospace' font-size='38' font-weight='700' fill='%23ffffff' text-anchor='middle'>APC</text></svg>">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;500;600;700&family=IBM+Plex+Sans:wght@400;500;600&display=swap">
    <link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;500;600;700&family=IBM+Plex+Sans:wght@400;500;600&display=swap" rel="stylesheet" media="print" onload="this.media='all'">
    <noscript><link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;500;600;700&family=IBM+Plex+Sans:wght@400;500;600&display=swap" rel="stylesheet"></noscript>
    <link rel="stylesheet" href="/base.css">
    <link rel="me" href="https://scalewithsearch.com">
    <link rel="me" href="https://victorvalentineromo.com">
    <link rel="me" href="https://aifirstsearch.com">
    <link rel="me" href="https://browserprompt.com">
    <link rel="me" href="https://creatinepedia.com">
    <link rel="me" href="https://polytraffic.com">
    <link rel="me" href="https://tattooremovalnear.com">
    <link rel="me" href="https://comicstripai.com">
    <link rel="me" href="https://aipaypercrawl.com">
    <link rel="me" href="https://b2bvic.com">
    <link rel="me" href="https://seobyrole.com">
    <link rel="me" href="https://quickfixseo.com">
</head>
<body>


  <nav class="nav" role="navigation" aria-label="Primary">
    <div class="nav__inner">
      <a href="/" class="nav__logo">APC</a>

      <div class="nav__links">
        <!-- Implementation dropdown -->
        <div class="mega-wrapper" data-mega="implementation">
          <button class="nav__link mega-trigger" aria-expanded="false" aria-controls="mega-implementation">
            Implementation
            <svg fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/></svg>
          </button>
        </div>

        <!-- Pricing dropdown -->
        <div class="mega-wrapper" data-mega="pricing">
          <button class="nav__link mega-trigger" aria-expanded="false" aria-controls="mega-pricing">
            Pricing
            <svg fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/></svg>
          </button>
        </div>

        <!-- Crawlers dropdown -->
        <div class="mega-wrapper" data-mega="crawlers">
          <button class="nav__link mega-trigger" aria-expanded="false" aria-controls="mega-crawlers">
            Crawlers
            <svg fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/></svg>
          </button>
        </div>

        <!-- Legal (direct link) -->
        <a href="/articles.html" class="nav__link">Legal</a>

        <div class="nav__divider"></div>

        <a href="/setup.html" class="nav__cta">Master the Protocol &mdash; $2,497</a>
      </div>

      <button class="nav__mobile-btn" id="mobile-menu-btn" aria-label="Open menu">
        <svg id="menu-icon" width="24" height="24" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16M4 18h16"/></svg>
        <svg id="close-icon" class="hidden" width="24" height="24" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18L18 6M6 6l12 12"/></svg>
      </button>
    </div>

    <!-- Mega Panel: Implementation -->
    <div id="mega-implementation" class="mega-panel" role="region" aria-label="Implementation guides">
      <div class="mega-panel__inner">
        <div>
          <div class="mega-column__label">Infrastructure</div>
          <a href="/articles.html" class="mega-link">Cloudflare Setup</a>
          <a href="/articles.html" class="mega-link">Nginx Rules</a>
          <a href="/articles.html" class="mega-link">Apache Config</a>
          <a href="/articles.html" class="mega-link">WordPress Plugin</a>
          <a href="/articles.html" class="mega-link">CDN Integration</a>
        </div>
        <div>
          <div class="mega-column__label">Protocols</div>
          <a href="/articles.html" class="mega-link">RSL Protocol</a>
          <a href="/articles.html" class="mega-link">llms.txt Specification</a>
          <a href="/articles.html" class="mega-link">robots.txt for AI</a>
          <a href="/articles.html" class="mega-link">Machine-Readable Terms</a>
        </div>
        <div>
          <div class="mega-column__label">Quick Start</div>
          <div style="background: linear-gradient(135deg, rgba(16,185,129,0.06), rgba(79,70,229,0.04)); border: 1px solid rgba(16,185,129,0.2); border-radius: 12px; padding: 1.5rem;">
            <h3 style="font-family: var(--font-display); font-size: 1.125rem; font-weight: 600; color: var(--text-primary); margin-bottom: 0.5rem;">Skip the learning curve.</h3>
            <p style="font-size: 0.875rem; color: var(--text-secondary); margin-bottom: 1rem;">Complete pay-per-crawl implementation. Templates, pricing, contracts.</p>
            <a href="/setup.html" class="btn btn--primary" style="font-size: 0.8125rem; padding: 0.625rem 1.25rem;">Get Rule &mdash; $2,497</a>
          </div>
        </div>
      </div>
    </div>

    <!-- Mega Panel: Pricing -->
    <div id="mega-pricing" class="mega-panel" role="region" aria-label="Pricing models">
      <div class="mega-panel__inner">
        <div>
          <div class="mega-column__label">Models</div>
          <a href="/articles.html" class="mega-link">Per-Crawl Pricing</a>
          <a href="/articles.html" class="mega-link">Flat-Rate Annual</a>
          <a href="/articles.html" class="mega-link">Tiered Pricing</a>
          <a href="/articles.html" class="mega-link">Volume Discounts</a>
          <a href="/articles.html" class="mega-link">Hybrid Models</a>
        </div>
        <div>
          <div class="mega-column__label">Benchmarks</div>
          <a href="/articles.html" class="mega-link">Rate Cards by Content Type</a>
          <a href="/articles.html" class="mega-link">Revenue Calculators</a>
          <a href="/articles.html" class="mega-link">Industry Benchmarks</a>
          <a href="/articles.html" class="mega-link">Deal Comparisons</a>
        </div>
        <div>
          <div class="mega-column__label">Recent Deals</div>
          <a href="/articles.html" class="mega-link">News Corp &times; OpenAI ($250M)</a>
          <a href="/articles.html" class="mega-link">Reddit &times; Google ($60M/yr)</a>
          <a href="/articles.html" class="mega-link">FT &times; Anthropic</a>
          <a href="/articles.html" class="mega-link">AP &times; OpenAI</a>
        </div>
      </div>
    </div>

    <!-- Mega Panel: Crawlers -->
    <div id="mega-crawlers" class="mega-panel" role="region" aria-label="Crawler information">
      <div class="mega-panel__inner">
        <div>
          <div class="mega-column__label">Major Crawlers</div>
          <a href="/articles.html" class="mega-link">GPTBot (OpenAI)</a>
          <a href="/articles.html" class="mega-link">ClaudeBot (Anthropic)</a>
          <a href="/articles.html" class="mega-link">Googlebot-Extended</a>
          <a href="/articles.html" class="mega-link">Bytespider (ByteDance)</a>
          <a href="/articles.html" class="mega-link">CCBot (Common Crawl)</a>
        </div>
        <div>
          <div class="mega-column__label">Detection</div>
          <a href="/articles.html" class="mega-link">Bot Detection Methods</a>
          <a href="/articles.html" class="mega-link">User Agent Reference</a>
          <a href="/articles.html" class="mega-link">IP Range Verification</a>
          <a href="/articles.html" class="mega-link">Compliance Rates</a>
        </div>
        <div>
          <div class="mega-column__label">Directory</div>
          <a href="/articles.html" class="mega-link">Full Crawler Directory</a>
          <a href="/articles.html" class="mega-link">Crawler Behavior Matrix</a>
          <a href="/articles.html" class="mega-link">robots.txt Respect Rates</a>
        </div>
      </div>
    </div>

    <!-- Mobile Menu -->
    <div id="mobile-menu" class="mobile-menu">
      <a href="/articles.html" class="mobile-menu__link">Implementation</a>
      <a href="/articles.html" class="mobile-menu__link">Pricing</a>
      <a href="/articles.html" class="mobile-menu__link">Crawlers</a>
      <a href="/articles.html" class="mobile-menu__link">Legal</a>
      <a href="/articles.html" class="mobile-menu__link">All Articles</a>
      <a href="/setup.html" class="mobile-menu__cta">Master the Protocol &mdash; $2,497</a>
    </div>
  </nav>

  <main class="pt-nav">
    <div class="container--narrow" style="padding-top: var(--sp-8);">
      <div class="breadcrumbs">
        <a href="/">Home</a><span class="breadcrumbs__sep">/</span>
        <a href="/articles.html">Articles</a><span class="breadcrumbs__sep">/</span>
        <span>ai crawler user agent strings</span>
      </div>

      <header style="margin-bottom: var(--sp-12);">
        <span class="label" style="margin-bottom: var(--sp-4); display: block;">Article &middot; 9 min read</span>
        <h1>ai crawler user agent strings</h1>
        <p style="font-size: 1.125rem; color: var(--text-secondary); margin-top: var(--sp-4); max-width: 640px;"></p>
      </header>

      <article class="article-body">
        <p>title:: AI Crawler User Agent Strings: Complete Reference Table
description:: Complete reference table of every known AI crawler user agent string. Includes GPTBot, ClaudeBot, Bytespider, Google-Extended, and 30+ other AI bot identifiers.
focus_keyword:: ai crawler user agent strings list
category:: crawlers
author:: Victor Valentine Romo
date:: 2026.02.07</p>
<h1>AI Crawler User Agent Strings: Complete Reference Table</h1>
<p>Every AI crawler identifies itself through a user-agent string in HTTP request headers. These strings are the first line of identification — the label that tells your server who&#39;s knocking. Without an accurate, current reference of AI crawler user-agent strings, you&#39;re blind to which AI companies are extracting your content and how much they&#39;re taking.</p>
<p>This reference table covers every documented AI crawler user-agent string as of early 2026. It serves as the foundation for <a href="/articles/server-level-ai-bot-blocking.html">server-level blocking</a>, <a href="/articles/detect-ai-crawlers-server-logs.html">analytics dashboards</a>, and <a href="/articles/cloudflare-pay-per-crawl-setup.html">monetization configurations</a>. Bookmark it. Your robots.txt and Nginx configurations depend on it.</p>
<hr>
<h2>Major AI Training Crawlers</h2>
<p>These crawlers collect content for permanent incorporation into AI model training datasets.</p>
<h3>OpenAI Crawlers</h3>
<table>
<thead>
<tr>
<th>User-Agent String</th>
<th>Purpose</th>
<th>Compliance</th>
<th>Monetizable</th>
</tr>
</thead>
<tbody><tr>
<td><code>GPTBot/1.0 (+https://openai.com/gptbot)</code></td>
<td>Model training and pre-indexing</td>
<td>High</td>
<td>Yes (Pay-Per-Crawl)</td>
</tr>
<tr>
<td><code>ChatGPT-User</code></td>
<td>Real-time browsing for ChatGPT</td>
<td>High</td>
<td>Limited</td>
</tr>
<tr>
<td><code>OAI-SearchBot/1.0</code></td>
<td>SearchGPT web retrieval</td>
<td>High</td>
<td>Emerging</td>
</tr>
</tbody></table>
<p><strong>GPTBot</strong> is the primary training crawler. <strong>ChatGPT-User</strong> is the real-time retrieval agent. <strong>OAI-SearchBot</strong> serves <strong>OpenAI</strong>&#39;s search product. Each requires separate robots.txt directives for independent control.</p>
<p>Full profile: <a href="/articles/gptbot-crawler-profile.html">GPTBot Crawler Profile</a></p>
<h3>Anthropic Crawlers</h3>
<table>
<thead>
<tr>
<th>User-Agent String</th>
<th>Purpose</th>
<th>Compliance</th>
<th>Monetizable</th>
</tr>
</thead>
<tbody><tr>
<td><code>ClaudeBot/1.0 (+https://anthropic.com/claudebot)</code></td>
<td>Model training data</td>
<td>Very high</td>
<td>Yes (Pay-Per-Crawl)</td>
</tr>
<tr>
<td><code>ClaudeBot-User/1.0 (+https://anthropic.com/claudebot)</code></td>
<td>Real-time retrieval</td>
<td>Very high</td>
<td>Limited</td>
</tr>
</tbody></table>
<p><strong>ClaudeBot</strong> demonstrates the highest compliance rate among major AI crawlers. Separate directives for <strong>ClaudeBot</strong> and <strong>ClaudeBot-User</strong> enable independent control of training vs. retrieval.</p>
<p>Full profile: <a href="/articles/claudebot-crawler-profile.html">ClaudeBot Crawler Profile</a></p>
<h3>Google Crawlers</h3>
<table>
<thead>
<tr>
<th>User-Agent String</th>
<th>Purpose</th>
<th>Compliance</th>
<th>Monetizable</th>
</tr>
</thead>
<tbody><tr>
<td><code>Googlebot</code> (standard)</td>
<td>Search indexing</td>
<td>Very high</td>
<td>N/A (search)</td>
</tr>
<tr>
<td><code>Google-Extended</code></td>
<td>AI training (Gemini)</td>
<td>High</td>
<td>Licensing deals</td>
</tr>
</tbody></table>
<p><strong>Google-Extended</strong> is a permission token, not a separate crawler. It shares infrastructure with <strong>Googlebot</strong>. Blocking <strong>Google-Extended</strong> prevents AI training use without affecting search indexing.</p>
<p>Full profile: <a href="/articles/google-extended-crawler-profile.html">Google-Extended Crawler Profile</a></p>
<h3>ByteDance Crawlers</h3>
<table>
<thead>
<tr>
<th>User-Agent String</th>
<th>Purpose</th>
<th>Compliance</th>
<th>Monetizable</th>
</tr>
</thead>
<tbody><tr>
<td><code>Bytespider</code></td>
<td>AI training (Doubao, TikTok)</td>
<td>Very low</td>
<td>No</td>
</tr>
<tr>
<td><code>Mozilla/5.0 (compatible; Bytespider; spider-feedback@bytedance.com)</code></td>
<td>Same (extended format)</td>
<td>Very low</td>
<td>No</td>
</tr>
</tbody></table>
<p><strong>Bytespider</strong> frequently spoofs its user-agent string, appearing as standard browsers. User-agent detection alone is insufficient — combine with <a href="/articles/block-bytespider-nginx.html">IP/ASN blocking</a>.</p>
<p>Full profile: <a href="/articles/bytespider-crawler-profile.html">Bytespider Crawler Profile</a></p>
<h3>Meta Crawlers</h3>
<table>
<thead>
<tr>
<th>User-Agent String</th>
<th>Purpose</th>
<th>Compliance</th>
<th>Monetizable</th>
</tr>
</thead>
<tbody><tr>
<td><code>Meta-ExternalAgent/1.0 (+https://developers.facebook.com/docs/sharing/webmasters/crawler)</code></td>
<td>AI training (LLaMA)</td>
<td>Moderate-high</td>
<td>Limited</td>
</tr>
<tr>
<td><code>facebookexternalhit/1.1</code></td>
<td>Social sharing previews</td>
<td>N/A</td>
<td>N/A (keep allowed)</td>
</tr>
<tr>
<td><code>Facebot</code></td>
<td>Social features</td>
<td>N/A</td>
<td>N/A (keep allowed)</td>
</tr>
</tbody></table>
<p>Block <strong>Meta-ExternalAgent</strong> for AI training opt-out. Do NOT block <strong>facebookexternalhit</strong> or <strong>Facebot</strong> — these handle link previews on Facebook and Instagram.</p>
<p>Full profile: <a href="/articles/meta-ai-crawler-profile.html">Meta AI Crawler Profile</a></p>
<h3>Amazon Crawlers</h3>
<table>
<thead>
<tr>
<th>User-Agent String</th>
<th>Purpose</th>
<th>Compliance</th>
<th>Monetizable</th>
</tr>
</thead>
<tbody><tr>
<td><code>Amazonbot/0.1 (https://developer.amazon.com/support/amazonbot)</code></td>
<td>AI training (Alexa, Rufus, Q)</td>
<td>High</td>
<td>Limited</td>
</tr>
</tbody></table>
<p>Full profile: <a href="/articles/amazonbot-crawler-profile.html">Amazonbot Crawler Profile</a></p>
<h3>Apple Crawlers</h3>
<table>
<thead>
<tr>
<th>User-Agent String</th>
<th>Purpose</th>
<th>Compliance</th>
<th>Monetizable</th>
</tr>
</thead>
<tbody><tr>
<td><code>Applebot-Extended</code></td>
<td>AI training (Apple Intelligence)</td>
<td>High</td>
<td>Limited</td>
</tr>
<tr>
<td><code>Applebot/0.1 (+http://www.apple.com/go/applebot)</code></td>
<td>Siri/Spotlight (keep allowed)</td>
<td>Very high</td>
<td>N/A</td>
</tr>
</tbody></table>
<p>Block <strong>Applebot-Extended</strong> for AI training opt-out. Keep <strong>Applebot</strong> allowed for Siri knowledge features.</p>
<p>Full profile: <a href="/articles/applebot-extended-crawler-profile.html">Applebot-Extended Crawler Profile</a></p>
<h3>Common Crawl</h3>
<table>
<thead>
<tr>
<th>User-Agent String</th>
<th>Purpose</th>
<th>Compliance</th>
<th>Monetizable</th>
</tr>
</thead>
<tbody><tr>
<td><code>CCBot/2.0 (https://commoncrawl.org/faq/)</code></td>
<td>Open training datasets</td>
<td>High</td>
<td>No (nonprofit)</td>
</tr>
</tbody></table>
<p>Blocking <strong>CCBot</strong> denies training data to dozens of AI companies simultaneously. The highest-leverage single block.</p>
<p>Full profile: <a href="/articles/ccbot-common-crawl-profile.html">CCBot Profile</a></p>
<hr>
<h2>AI Search and Retrieval Crawlers</h2>
<p>These crawlers fetch content for real-time query answering rather than permanent model training.</p>
<h3>Perplexity</h3>
<table>
<thead>
<tr>
<th>User-Agent String</th>
<th>Purpose</th>
<th>Compliance</th>
<th>Monetizable</th>
</tr>
</thead>
<tbody><tr>
<td><code>PerplexityBot</code></td>
<td>AI search retrieval</td>
<td>Disputed</td>
<td>Limited</td>
</tr>
</tbody></table>
<p><strong>PerplexityBot</strong> has faced <a href="/articles/perplexity-scraping-controversy.html">scraping controversies</a> over robots.txt compliance and content attribution.</p>
<h3>Cohere</h3>
<table>
<thead>
<tr>
<th>User-Agent String</th>
<th>Purpose</th>
<th>Compliance</th>
<th>Monetizable</th>
</tr>
</thead>
<tbody><tr>
<td><code>cohere-ai</code></td>
<td>Enterprise AI retrieval</td>
<td>Moderate</td>
<td>Limited</td>
</tr>
</tbody></table>
<p><strong>Cohere</strong> operates primarily in enterprise RAG deployments.</p>
<h3>You.com</h3>
<table>
<thead>
<tr>
<th>User-Agent String</th>
<th>Purpose</th>
<th>Compliance</th>
<th>Monetizable</th>
</tr>
</thead>
<tbody><tr>
<td><code>YouBot</code></td>
<td>AI search</td>
<td>Moderate</td>
<td>No</td>
</tr>
</tbody></table>
<hr>
<h2>Emerging and Specialized AI Crawlers</h2>
<h3>Mistral</h3>
<table>
<thead>
<tr>
<th>User-Agent String</th>
<th>Purpose</th>
<th>Compliance</th>
</tr>
</thead>
<tbody><tr>
<td><code>MistralBot</code></td>
<td>Model training</td>
<td>Moderate</td>
</tr>
</tbody></table>
<h3>AI21 Labs</h3>
<table>
<thead>
<tr>
<th>User-Agent String</th>
<th>Purpose</th>
<th>Compliance</th>
</tr>
</thead>
<tbody><tr>
<td><code>AI2Bot</code></td>
<td>Research and training</td>
<td>High</td>
</tr>
</tbody></table>
<h3>Hugging Face</h3>
<table>
<thead>
<tr>
<th>User-Agent String</th>
<th>Purpose</th>
<th>Compliance</th>
</tr>
</thead>
<tbody><tr>
<td><code>HuggingFaceBot</code></td>
<td>Model training datasets</td>
<td>Moderate</td>
</tr>
</tbody></table>
<h3>DeepSeek</h3>
<table>
<thead>
<tr>
<th>User-Agent String</th>
<th>Purpose</th>
<th>Compliance</th>
</tr>
</thead>
<tbody><tr>
<td><code>Deepseekbot</code></td>
<td>Model training</td>
<td>Low-Moderate</td>
</tr>
</tbody></table>
<h3>Baidu (ERNIE)</h3>
<table>
<thead>
<tr>
<th>User-Agent String</th>
<th>Purpose</th>
<th>Compliance</th>
</tr>
</thead>
<tbody><tr>
<td><code>Baiduspider</code></td>
<td>Search + AI training</td>
<td>Moderate</td>
</tr>
</tbody></table>
<p>Note: <strong>Baiduspider</strong> serves both traditional search and AI training for <strong>Baidu</strong>&#39;s ERNIE models. Blocking it may affect your visibility in Baidu search (relevant for Chinese audience).</p>
<h3>Others</h3>
<table>
<thead>
<tr>
<th>User-Agent String</th>
<th>Operator</th>
<th>Purpose</th>
</tr>
</thead>
<tbody><tr>
<td><code>Diffbot</code></td>
<td>Diffbot</td>
<td>Knowledge graph construction</td>
</tr>
<tr>
<td><code>Webzio-Extended</code></td>
<td>Webz.io</td>
<td>Data feeds for AI companies</td>
</tr>
<tr>
<td><code>Scrapy</code></td>
<td>Various</td>
<td>Generic scraping framework (not specific to one company)</td>
</tr>
<tr>
<td><code>DataForSeoBot</code></td>
<td>DataForSEO</td>
<td>SEO data + AI features</td>
</tr>
<tr>
<td><code>SemrushBot</code></td>
<td>Semrush</td>
<td>SEO data + AI features</td>
</tr>
<tr>
<td><code>AhrefsBot</code></td>
<td>Ahrefs</td>
<td>SEO data + AI features</td>
</tr>
<tr>
<td><code>PetalBot</code></td>
<td>Huawei</td>
<td>Search + AI (Petal Search)</td>
</tr>
<tr>
<td><code>ImagesiftBot</code></td>
<td>Imagesift</td>
<td>Image training data</td>
</tr>
</tbody></table>
<hr>
<h2>Detection Patterns for Server Configuration</h2>
<h3>Nginx Map for All Known AI Crawlers</h3>
<pre><code class="language-nginx">map $http_user_agent $is_ai_crawler {
    default 0;
    ~*GPTBot 1;
    ~*ChatGPT-User 1;
    ~*OAI-SearchBot 1;
    ~*ClaudeBot 1;
    ~*Bytespider 1;
    ~*bytedance 1;
    ~*Google-Extended 1;
    ~*Meta-ExternalAgent 1;
    ~*Amazonbot 1;
    ~*Applebot-Extended 1;
    ~*CCBot 1;
    ~*PerplexityBot 1;
    ~*cohere-ai 1;
    ~*YouBot 1;
    ~*MistralBot 1;
    ~*AI2Bot 1;
    ~*Deepseekbot 1;
    ~*Diffbot 1;
    ~*PetalBot 1;
    ~*ImagesiftBot 1;
}
</code></pre>
<p>Use <code>$is_ai_crawler</code> in conditional blocks for blanket AI crawler management.</p>
<h3>Separate Training vs. Search Classification</h3>
<pre><code class="language-nginx"># Training crawlers
map $http_user_agent $is_ai_training_crawler {
    default 0;
    ~*GPTBot 1;
    ~*ClaudeBot/1 1;
    ~*Google-Extended 1;
    ~*Meta-ExternalAgent 1;
    ~*Bytespider 1;
    ~*bytedance 1;
    ~*CCBot 1;
    ~*Amazonbot 1;
    ~*Applebot-Extended 1;
    ~*MistralBot 1;
    ~*Deepseekbot 1;
}

# Search/retrieval crawlers
map $http_user_agent $is_ai_search_crawler {
    default 0;
    ~*ChatGPT-User 1;
    ~*ClaudeBot-User 1;
    ~*PerplexityBot 1;
    ~*cohere-ai 1;
    ~*YouBot 1;
    ~*OAI-SearchBot 1;
}
</code></pre>
<p>This enables the <a href="/articles/ai-search-vs-training-crawlers.html">dual strategy</a>: block training, allow search.</p>
<h3>Apache .htaccess Pattern</h3>
<pre><code class="language-apache"># Block all known AI training crawlers
RewriteCond %{HTTP_USER_AGENT} (GPTBot|ClaudeBot/1|Google-Extended|Meta-ExternalAgent|Bytespider|bytedance|CCBot|Amazonbot|Applebot-Extended|MistralBot|Deepseekbot) [NC]
RewriteRule .* - [F,L]
</code></pre>
<hr>
<h2>Keeping This List Current</h2>
<h3>Why User-Agent Lists Decay</h3>
<p>AI crawler user-agent strings change. New AI companies emerge. Existing companies deploy new crawlers. User-agent formats evolve. A list accurate in January 2026 will have gaps by June 2026.</p>
<p>Sources for updates:</p>
<ol>
<li><strong>Cloudflare Radar</strong> — Publishes bot traffic data including new user agents</li>
<li><strong>Dark Visitors</strong> (darkvisitors.com) — Community-maintained AI crawler database</li>
<li><strong>Server log analysis</strong> — Your own logs reveal crawlers not yet publicly documented</li>
<li><strong>AI company documentation</strong> — Official crawler pages from OpenAI, Anthropic, Google, etc.</li>
<li><strong>Publisher forums and trade publications</strong> — Early reports of new crawler activity</li>
</ol>
<h3>Monthly Audit Process</h3>
<ol>
<li>Review access logs for unrecognized user agents with high request volumes</li>
<li>Cross-reference new agents against known AI company IP ranges</li>
<li>Check behavioral patterns (systematic crawling vs. legitimate browser behavior)</li>
<li>Update Nginx maps, robots.txt, and CDN rules with new entries</li>
<li>Remove deprecated entries (crawlers that no longer operate)</li>
</ol>
<p>The <a href="/articles/ai-crawler-audit-walkthrough.html">AI crawler audit walkthrough</a> provides the complete step-by-step process.</p>
<hr>
<h2>Spoofing and Verification</h2>
<h3>The Trust Problem</h3>
<p>User-agent strings are self-reported. Any HTTP client can claim any identity. A scraper can set its user-agent to <code>Googlebot</code> and your server would see a request apparently from <strong>Google</strong>. This makes user-agent matching necessary but insufficient.</p>
<h3>Verification Methods by Crawler</h3>
<table>
<thead>
<tr>
<th>Crawler</th>
<th>Verification Method</th>
</tr>
</thead>
<tbody><tr>
<td><strong>GPTBot</strong></td>
<td>IP range check (20.15.240.x ranges)</td>
</tr>
<tr>
<td><strong>ClaudeBot</strong></td>
<td>IP range check (160.79.104.0/23)</td>
</tr>
<tr>
<td><strong>Googlebot</strong></td>
<td>Reverse DNS (*.googlebot.com)</td>
</tr>
<tr>
<td><strong>Applebot</strong></td>
<td>Reverse DNS (*.applebot.apple.com)</td>
</tr>
<tr>
<td><strong>Bingbot</strong></td>
<td>Reverse DNS (*.search.msn.com)</td>
</tr>
<tr>
<td><strong>Bytespider</strong></td>
<td>ASN check (AS396986, AS138294)</td>
</tr>
<tr>
<td>Most others</td>
<td>No official verification method</td>
</tr>
</tbody></table>
<p>For crawlers without official IP ranges, behavioral analysis provides secondary verification. Legitimate AI crawlers exhibit consistent patterns — systematic access, regular intervals, coverage of content sections. Spoofed crawlers often show erratic patterns — random pages, irregular timing, combined with other suspicious activity.</p>
<p>The <a href="/articles/ai-crawler-ip-verification.html">IP verification guide</a> covers verification methods in detail.</p>
<hr>
<h2>Frequently Asked Questions</h2>
<h3>How often do AI crawler user-agent strings change?</h3>
<p>Rarely for major crawlers. <strong>GPTBot</strong>, <strong>ClaudeBot</strong>, and <strong>CCBot</strong> have maintained stable user-agent strings since launch. New versions or format changes are typically documented by the operating company. The bigger risk is entirely new crawlers appearing from new AI companies — these require log monitoring to detect.</p>
<h3>Should I block all AI crawlers listed here?</h3>
<p>Not necessarily. The <a href="/articles/publisher-ai-crawler-decision-framework.html">publisher decision framework</a> helps determine which crawlers to block, which to monetize, and which to allow. Blanket blocking forfeits all AI licensing revenue. Selective blocking and monetization maximize both protection and revenue.</p>
<h3>What if a crawler doesn&#39;t identify itself with any known user-agent?</h3>
<p>Unidentified crawlers require behavioral detection. High request volumes, systematic access patterns, absence of CSS/JS/image requests, and requests from data center IP ranges (rather than residential or mobile) suggest bot activity. <a href="/articles/detect-ai-crawlers-server-logs.html">Server log analysis</a> and <a href="/articles/cloudflare-bot-management-ai.html">CDN bot management</a> tools help identify these unlabeled crawlers.</p>
<h3>Can I use this list for Cloudflare firewall rules?</h3>
<p>Yes. Create a Cloudflare WAF custom rule matching user-agent strings from this table. The rule can block, challenge, or log matching requests. For Pay-Per-Crawl publishers, Cloudflare&#39;s built-in AI crawler detection handles identification automatically — but manual rules provide backup coverage for crawlers not yet in Cloudflare&#39;s database.</p>
<h3>Where can I find real-time updates to this list?</h3>
<p>Monitor darkvisitors.com for community-maintained updates, Cloudflare Radar for bot traffic trends, and individual AI company documentation pages for official changes. Your own server logs are the most authoritative source — they show exactly which user agents are hitting your specific domain.</p>

      </article>

      <div class="cta-box" style="margin: var(--sp-16) 0;">
        <h3>Your Content Feeds AI. Get Paid for It.</h3>
        <p>Complete pay-per-crawl implementation. Templates, pricing models, licensing contracts. Everything.</p>
        <a href="/setup.html" class="btn btn--primary btn--large">Master the Protocol &mdash; $2,497</a>
      </div>

      <div style="margin-top: var(--sp-8); padding-top: var(--sp-8); border-top: 1px solid var(--border);">
        <a href="/articles.html" style="font-family: var(--font-mono); font-size: 0.875rem; font-weight: 500; color: var(--accent);">&larr; All Articles</a>
      </div>
    </div>
  </main>


  <footer class="footer">
    <div class="container">
      <div class="footer__grid">
        <div class="footer__brand">
          <div class="footer__logo">AI Pay Per Crawl</div>
          <p class="footer__desc">Your content feeds AI. The protocol ensures you get paid for it. Implementation guides, pricing models, and licensing infrastructure for publishers monetizing AI crawler traffic.</p>
          <a href="/setup.html" class="btn btn--primary" style="font-size: 0.8125rem; padding: 0.625rem 1.25rem;">Get Rule &mdash; $2,497</a>
        </div>

        <div>
          <div class="footer__heading">Implementation</div>
          <ul class="footer__links">
            <li><a href="/articles.html">Cloudflare Setup</a></li>
            <li><a href="/articles.html">RSL Protocol</a></li>
            <li><a href="/articles.html">llms.txt Guide</a></li>
            <li><a href="/articles.html">Nginx Rules</a></li>
            <li><a href="/articles.html">Apache Config</a></li>
            <li><a href="/articles.html">WordPress Plugin</a></li>
            <li><a href="/articles.html">CDN Integration</a></li>
            <li><a href="/articles.html">robots.txt Templates</a></li>
          </ul>
        </div>

        <div>
          <div class="footer__heading">Pricing &amp; Tools</div>
          <ul class="footer__links">
            <li><a href="/articles.html">Pricing Models</a></li>
            <li><a href="/articles.html">Rate Cards</a></li>
            <li><a href="/articles.html">Revenue Calculator</a></li>
            <li><a href="/articles.html">Crawler Directory</a></li>
            <li><a href="/articles.html">Bot Detection</a></li>
            <li><a href="/articles.html">Compliance Rates</a></li>
            <li><a href="/articles.html">Deal Analysis</a></li>
            <li><a href="/articles.html">Licensing Templates</a></li>
          </ul>
        </div>

        <div>
          <div class="footer__heading">From Scale With Search</div>
          <ul class="footer__links">
            <li><a href="https://scalewithsearch.com" target="_blank" rel="me">Scale With Search</a></li>
            <li><a href="https://aifirstsearch.com" target="_blank" rel="me">AI First Search</a></li>
            <li><a href="https://browserprompt.com" target="_blank" rel="me">Browser Prompt</a></li>
            <li><a href="https://polytraffic.com" target="_blank" rel="me">Polytraffic</a></li>
            <li><a href="https://creatinepedia.com" target="_blank" rel="me">Creatinepedia</a></li>
            <li><a href="https://victorvalentineromo.com" target="_blank" rel="me">Victor Romo</a></li>
            <li><a href="https://b2bvic.com" target="_blank" rel="me">B2B Vic</a></li>
          </ul>
        </div>
      </div>

      <div class="footer__bar">
        <p>&copy; 2026 AI Pay Per Crawl. Built by <a href="https://victorvalentineromo.com" target="_blank">Victor Valentine Romo</a>.</p>
        <p>A <a href="https://scalewithsearch.com" target="_blank">Scale With Search</a> property.</p>
      </div>
    </div>
  </footer>


  <script>
    /* Mega menu */
    (function() {
      var triggers = document.querySelectorAll('.mega-trigger');
      var panels = document.querySelectorAll('.mega-panel');
      var closeTimeout = null;

      function openPanel(id) {
        clearTimeout(closeTimeout);
        panels.forEach(function(p) { p.classList.remove('mega-panel--open'); });
        triggers.forEach(function(t) { t.setAttribute('aria-expanded', 'false'); });
        var panel = document.getElementById('mega-' + id);
        var trigger = document.querySelector('[data-mega="' + id + '"] .mega-trigger');
        if (panel) panel.classList.add('mega-panel--open');
        if (trigger) trigger.setAttribute('aria-expanded', 'true');
      }

      function scheduleClose() {
        closeTimeout = setTimeout(function() {
          panels.forEach(function(p) { p.classList.remove('mega-panel--open'); });
          triggers.forEach(function(t) { t.setAttribute('aria-expanded', 'false'); });
        }, 200);
      }

      function cancelClose() { clearTimeout(closeTimeout); }

      triggers.forEach(function(btn) {
        var wrapper = btn.closest('[data-mega]');
        var id = wrapper.getAttribute('data-mega');
        btn.addEventListener('mouseenter', function() { openPanel(id); });
        btn.addEventListener('click', function(e) {
          e.preventDefault();
          var panel = document.getElementById('mega-' + id);
          if (panel && panel.classList.contains('mega-panel--open')) {
            panel.classList.remove('mega-panel--open');
            btn.setAttribute('aria-expanded', 'false');
          } else {
            openPanel(id);
          }
        });
        wrapper.addEventListener('mouseleave', scheduleClose);
      });

      panels.forEach(function(panel) {
        panel.addEventListener('mouseenter', cancelClose);
        panel.addEventListener('mouseleave', scheduleClose);
      });

      document.addEventListener('click', function(e) {
        if (!e.target.closest('[data-mega]') && !e.target.closest('.mega-panel')) {
          panels.forEach(function(p) { p.classList.remove('mega-panel--open'); });
          triggers.forEach(function(t) { t.setAttribute('aria-expanded', 'false'); });
        }
      });

      document.addEventListener('keydown', function(e) {
        if (e.key === 'Escape') {
          panels.forEach(function(p) { p.classList.remove('mega-panel--open'); });
          triggers.forEach(function(t) { t.setAttribute('aria-expanded', 'false'); });
        }
      });
    })();

    /* Mobile menu */
    var mobileMenuBtn = document.getElementById('mobile-menu-btn');
    var mobileMenu = document.getElementById('mobile-menu');
    var menuIcon = document.getElementById('menu-icon');
    var closeIcon = document.getElementById('close-icon');
    if (mobileMenuBtn) {
      mobileMenuBtn.addEventListener('click', function() {
        mobileMenu.classList.toggle('mobile-menu--open');
        menuIcon.classList.toggle('hidden');
        closeIcon.classList.toggle('hidden');
      });
    }

    /* Self-link neutralizer */
    (function() {
      var currentPath = window.location.pathname.replace(/\.html$/, '').replace(/\/$/, '') || '/';
      document.querySelectorAll('a[href]').forEach(function(a) {
        var href = a.getAttribute('href').replace(/\.html$/, '').replace(/\/$/, '') || '/';
        if (href === currentPath) {
          a.removeAttribute('href');
          a.setAttribute('aria-current', 'page');
          a.style.opacity = '0.5';
          a.style.pointerEvents = 'none';
        }
      });
    })();

    /* Copy code button */
    function copyCode(button) {
      var codeBlock = button.closest('.code-block');
      var code = codeBlock.querySelector('code').innerText;
      navigator.clipboard.writeText(code).then(function() {
        button.textContent = 'Copied!';
        setTimeout(function() { button.textContent = 'Copy'; }, 2000);
      });
    }

    /* FAQ Accordion */
    document.querySelectorAll('.accordion__trigger').forEach(function(trigger) {
      trigger.addEventListener('click', function() {
        var expanded = this.getAttribute('aria-expanded') === 'true';
        var body = this.nextElementSibling;
        this.setAttribute('aria-expanded', !expanded);
        body.classList.toggle('accordion__body--open');
      });
    });
  </script>
</body>
</html>